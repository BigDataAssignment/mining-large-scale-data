{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program\n",
    "Author: Owen Fava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from empath import Empath\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.mapper import FullBatchNodeGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "from stellargraph.layer import GraphConvolution\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nltk.download(\"words\")\n",
    "nltk.download('vader_lexicon')\n",
    "psy_ner = spacy.load(\"./model/psy_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"Enter your input: \")\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    text = nlp(sentence)\n",
    "\n",
    "    preprocessing = \" \".join([token.lemma_ for token in text if not token.is_stop])\n",
    "    \n",
    "    words = preprocessing.split()\n",
    "    cleaned_sentence = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    return ' '.join(cleaned_sentence)\n",
    "\n",
    "# FOR TESTING PASS THIS SENTENCE: \"I am in a really dark moment in my life right now. My husband is a controlling pos that believes heâ€™s a doctor and doesnâ€™t allow me to get any kind of treatment for my BPD. I recently moved to his country and I am unable to do anything by myself (I donâ€™t speak Korean), also he keeps the salary of my job so I donâ€™t have money. I canâ€™t move back to my country either, my family stopped to talk to me because I married him, so how can I cope with all the suicide thoughts I have everyday? I also suffer from anger management issues and without medicine, I canâ€™t control myself and we fight a lot. I feel really lonely here, he works 24/7, but I prefer that than being with him honestly. Heâ€™s controlling and even violent sometimes. What do you recommend to treat my BPD?\"\n",
    "cleaned_sentence = clean_sentence(user_input)\n",
    "print(f\"Original sentence: {user_input}\")\n",
    "print(f\"Cleaned sentence: {cleaned_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = Empath()\n",
    "sentiment_intensity_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "data = pd.DataFrame(columns=[\"sentence\", \"psy_labels\", \"semantic_relationships\", \"sentiment\", \"emotional_categories\"])\n",
    "\n",
    "MH_NER = [\n",
    "    \"ANXIETY DISORDERS\",\n",
    "    \"BIPOLAR DISORDERS\",\n",
    "    \"DEPRESSIVE DISORDERS\",\n",
    "    \"DISRUPTIVE IMPULSE-CONTROL, AND CONDUCT DISORDERS\",\n",
    "    \"DISSOCIATIVE DISORDERS\",\n",
    "    \"EATING DISORDERS\",\n",
    "    \"NEURO-COGNITIVE DISORDERS\",\n",
    "    \"NEURO-DEVELOPMENTAL DISORDERS\",\n",
    "    \"OBSESSIVE-COMPULSIVE AND RELATED DISORDERS\",\n",
    "    \"PERSONALITY DISORDERS\",\n",
    "    \"PSYCHEDELIC DRUGS\",\n",
    "    \"SCHIZOPHRENIA SPECTRUM AND OTHER PSYCHOTIC DISORDERS\",\n",
    "    \"SEXUAL DYSFUNCTIONS\",\n",
    "    \"SLEEP-WAKE DISORDERS\",\n",
    "    \"SOMATIC SYMPTOM RELATED DISORDERS\",\n",
    "    \"SUBSTANCE-RELATED DISORDERS\",\n",
    "    \"SYMPTOMS\",\n",
    "    \"TRAUMA AND STRESS RELATED DISORDERS\",\n",
    "]\n",
    "\n",
    "EMPATH_CATS = [\n",
    "    \"help\",\n",
    "    \"violence\",\n",
    "    \"sleep\",\n",
    "    \"medical_emergency\",\n",
    "    \"cold\",\n",
    "    \"hate\",\n",
    "    \"cheerfulness\",\n",
    "    \"aggression\",\n",
    "    \"envy\",\n",
    "    \"anticipation\",\n",
    "    \"health\",\n",
    "    \"pride\",\n",
    "    \"nervousness\",\n",
    "    \"weakness\",\n",
    "    \"horror\",\n",
    "    \"swearing_terms\",\n",
    "    \"suffering\",\n",
    "    \"sexual\",\n",
    "    \"fear\",\n",
    "    \"monster\",\n",
    "    \"irritability\",\n",
    "    \"exasperation\",\n",
    "    \"ridicule\",\n",
    "    \"neglect\",\n",
    "    \"fight\",\n",
    "    \"dominant_personality\",\n",
    "    \"injury\",\n",
    "    \"rage\",\n",
    "    \"science\",\n",
    "    \"work\",\n",
    "    \"optimism\",\n",
    "    \"warmth\",\n",
    "    \"sadness\",\n",
    "    \"emotional\",\n",
    "    \"joy\",\n",
    "    \"shame\",\n",
    "    \"torment\",\n",
    "    \"anger\",\n",
    "    \"strength\",\n",
    "    \"ugliness\",\n",
    "    \"pain\",\n",
    "    \"negative_emotion\",\n",
    "    \"positive_emotion\",\n",
    "]\n",
    "\n",
    "def create_rel_feature(text):\n",
    "    def _extract_relations(text):\n",
    "        relations = []\n",
    "        if not isinstance(text, str):\n",
    "            return relations\n",
    "        \n",
    "        doc = nlp(text)\n",
    "\n",
    "        for sent in doc.sents:\n",
    "            for token in sent:\n",
    "                if token.dep_ in [\"nsubj\", \"dobj\"]:\n",
    "                    relations.append((token.head.text, token.dep_, token.text))\n",
    "        return relations\n",
    "\n",
    "    sentence_relationship = _extract_relations(text)\n",
    "\n",
    "    return sentence_relationship\n",
    "\n",
    "def create_psylabel_feature(text):\n",
    "    def _extract_psy_labels(text):\n",
    "        mh_labels = { }\n",
    "        if not isinstance(text, str):\n",
    "            return mh_labels\n",
    "\n",
    "        doc = psy_ner(text)\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in MH_NER:\n",
    "                if ent.label_ not in mh_labels:\n",
    "                    mh_labels[ent.label_] = set()\n",
    "                mh_labels[ent.label_].add(ent.text)\n",
    "        for label in mh_labels:\n",
    "            mh_labels[label] = list(mh_labels[label])\n",
    "        return mh_labels\n",
    "\n",
    "    combined_labels = _extract_psy_labels(text)\n",
    "\n",
    "    return combined_labels\n",
    "\n",
    "def create_sentiment_feature(text):\n",
    "    def _get_vader_sentiment(text):\n",
    "        score = sentiment_intensity_analyzer.polarity_scores(text)\n",
    "\n",
    "        return score[\"compound\"] if score is not None else np.NaN\n",
    "\n",
    "    combined_labels = _get_vader_sentiment(text)\n",
    "\n",
    "    return combined_labels\n",
    "\n",
    "def create_emotional_categories_scores_feature(text):\n",
    "    def _get_empath_sentiment(text):\n",
    "        scores = lexicon.analyze(text, categories=EMPATH_CATS, normalize=True)\n",
    "        if scores is not None:\n",
    "            return {category: round(score, 2) for category, score in scores.items()}\n",
    "        else:\n",
    "            return { }\n",
    "\n",
    "    combined_labels = _get_empath_sentiment(text)\n",
    "\n",
    "    return combined_labels\n",
    "\n",
    "data.loc[len(data)] = [cleaned_sentence, create_psylabel_feature(text=cleaned_sentence), create_rel_feature(text=cleaned_sentence), create_sentiment_feature(text=cleaned_sentence), create_emotional_categories_scores_feature(cleaned_sentence)]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "labels = data.iloc[0][\"psy_labels\"]\n",
    "relationships = data[\"semantic_relationships\"]\n",
    "sentence = data.iloc[0][\"sentence\"]\n",
    "\n",
    "for relationship in relationships:\n",
    "    for rel in relationship:\n",
    "        if len(rel) == 3:\n",
    "            word1, dep, word2 = rel\n",
    "            clean_data.append(\n",
    "                {\n",
    "                    \"Word1\": word1,\n",
    "                    \"Dependency\": dep,\n",
    "                    \"Word2\": word2,\n",
    "                    \"MHlabels\": labels,\n",
    "                    \"sentence\": sentence\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Issue with relationship: {rel}\")\n",
    "\n",
    "clean_data_frame = pd.DataFrame(clean_data)\n",
    "print(clean_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "\n",
    "for row in tqdm(clean_data_frame.itertuples(), total=len(clean_data_frame), desc=\"Processing Rows\", position=0):\n",
    "    word1_lowercase = row.Word1.lower()\n",
    "    graph.add_node(word1_lowercase)\n",
    "\n",
    "    word2_lowercase = row.Word2.lower()\n",
    "    graph.add_node(word2_lowercase)\n",
    "\n",
    "    mh_labels_dict = ast.literal_eval(str(row.MHlabels))\n",
    "\n",
    "    # Determine the relationship direction based on 'Dependency'\n",
    "    if row.Dependency == 'dobj':\n",
    "        graph.add_edge(word1_lowercase, word2_lowercase, dependency=row.Dependency, label={**mh_labels_dict})\n",
    "    elif row.Dependency == 'nsubj':\n",
    "        graph.add_edge(word1_lowercase, word2_lowercase, dependency=row.Dependency, label={**mh_labels_dict})\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "nx.draw(graph, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = KeyedVectors.load(\"word2vec_embeddings.bin\")\n",
    "\n",
    "node_to_remove = []\n",
    "\n",
    "for node in graph.nodes:\n",
    "    if node in word_embeddings.wv:\n",
    "        attrs = {node: {\"embedding\": word_embeddings.wv[node]}}\n",
    "        nx.set_node_attributes(graph, attrs)\n",
    "    else:\n",
    "       node_to_remove.append(node)\n",
    "\n",
    "for node in node_to_remove:\n",
    "    graph.remove_node(node)\n",
    "\n",
    "print(graph.nodes.data(True))\n",
    "nx.draw(graph, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data = {node: data for node, data in graph.nodes(data=True)}\n",
    "# node_df = pd.DataFrame.from_dict({(i): node_data[i][j] for i in node_data.keys() for j in node_data[i].keys()}, orient='index')\n",
    "# node_df.reset_index(inplace=True)\n",
    "# node_df.rename(columns={'level_0': 'node', 'level_1': 'attribute'}, inplace=True)\n",
    "# Create a mapping between string and numeric identifiers\n",
    "node_mapping = {node: idx for idx, node in enumerate(node_data.keys())}\n",
    "node_df = pd.DataFrame.from_dict({(node_mapping[node]): values[\"embedding\"] for node, values in node_data.items()}, orient=\"index\").reset_index()\n",
    "# print(node_df)\n",
    "\n",
    "edge_data = [(source, target, data) for source, target, data in graph.edges(data=True)]\n",
    "edge_df = pd.DataFrame(edge_data, columns=['source', 'target', 'edge_attribute'])\n",
    "source_nodes = edge_df[\"source\"]\n",
    "target_nodes = edge_df[\"target\"]\n",
    "edge_df = pd.concat([source_nodes, target_nodes], axis=1)\n",
    "edge_df.replace(node_mapping, inplace=True)\n",
    "\n",
    "stellar_graph = StellarGraph(nodes=node_df, edges=edge_df)\n",
    "print(stellar_graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"models/model_fold_1.h5\", custom_objects={\"GraphConvolution\": GraphConvolution})\n",
    "\n",
    "if model is not None:\n",
    "    print(\"Model is loaded\")\n",
    "else:\n",
    "    print(\"Model is not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = FullBatchNodeGenerator(stellar_graph, method=\"gcn\")\n",
    "new_data_gen = generator.flow(stellar_graph.nodes())\n",
    "\n",
    "predictions = model.predict(new_data_gen)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsd-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
