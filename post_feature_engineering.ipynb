{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Relationship Extraction and Feature Engineering\n",
    "\n",
    "By christian Spiteri Gauci and Adam Darmanin\n",
    "\n",
    "## Literature and References\n",
    "\n",
    "## Method\n",
    "\n",
    "* Cleaning of data - Remove special characters, punctuation, and extra whitespace\n",
    "* Tokenise using spacy\n",
    "* Lemmatize tokens and remove stopwords\n",
    "* extract relationships - using \"nsubj\", \"ROOT\", \"dobj\"\n",
    "* Clean the extracted relationships - remove any entries that inlcude only special characters or numbers\n",
    "* Remove entries that occur only once - and keep those that occur 3times or more in each subreddit \n",
    "* Remove entries that occur in more than one subreddit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamd\\AppData\\Local\\Temp\\ipykernel_11756\\1435294090.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\adamd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\adamd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import words as nltk_words\n",
    "\n",
    "\n",
    "from lib.sanitze_util import clean_text_batch\n",
    "\n",
    "tqdm.pandas()  # for progressbase in DFs.\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download(\"words\")\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "english_words = set(nltk_words.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "1. Clean stopwords\n",
    "2. Lemmatize\n",
    "3. Convert emoticons\n",
    "4. Expand contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamd\\AppData\\Local\\Temp\\ipykernel_11756\\2031721653.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  mask = df_subset.applymap(lambda x: isinstance(x, str) and x.strip() != \"\")\n",
      "Cleaning Pipeline Token:   0%|          | 0/738 [00:00<?, ?it/s]c:\\Users\\adamd\\workspace\\mining-large-scale-data\\lib\\sanitze_util.py:88: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n",
      "c:\\Users\\adamd\\.conda\\envs\\gnn\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "Cleaning Pipeline Token: 100%|██████████| 738/738 [00:00<00:00, 2435.64it/s]\n",
      "Cleaning Pipeline Token: 100%|██████████| 738/738 [00:02<00:00, 322.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/mental_disorders_reddit.csv\")\n",
    "\n",
    "# Create a new DataFrame with specific columns\n",
    "columns_needed = [\"title\", \"selftext\", \"subreddit\"]\n",
    "df_subset = df[columns_needed].copy()\n",
    "\n",
    "# Drop anything not a full peice of text in this dataset.\n",
    "mask = df_subset.applymap(lambda x: isinstance(x, str) and x.strip() != \"\")\n",
    "df_subset = df_subset[mask[\"title\"] & mask[\"selftext\"]]\n",
    "df_subset[\"raw_title\"] = df_subset[\"title\"]\n",
    "df_subset[\"raw_selftext\"] = df_subset[\"selftext\"]\n",
    "df_subset[\"title\"] = clean_text_batch(df_subset[\"title\"].fillna(\"\").tolist())\n",
    "df_subset[\"selftext\"] = clean_text_batch(df_subset[\"selftext\"].fillna(\"\").tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "1. Semantic relations between words\n",
    "2. Mental health labels in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\adamd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\adamd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "100%|██████████| 738/738 [00:03<00:00, 243.89it/s]\n",
      "100%|██████████| 738/738 [00:00<00:00, 1765.59it/s]\n",
      "100%|██████████| 738/738 [00:01<00:00, 483.94it/s]\n",
      "100%|██████████| 738/738 [00:11<00:00, 63.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>psy_labels</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotional_categories</th>\n",
       "      <th>semantic_relationships</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life pointless</td>\n",
       "      <td>think important life relationship like absolut...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>{'help': 0.0, 'violence': 0.0, 'sleep': 0.0, '...</td>\n",
       "      <td>[(ask, nsubj, relationship), (ask, dobj, goals)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>-0.9840</td>\n",
       "      <td>{'help': 0.01, 'violence': 0.01, 'sleep': 0.01...</td>\n",
       "      <td>[(discouraged, nsubj, spectrum), (discouraged,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know</td>\n",
       "      <td>f20 bf m20 told today said wish better likes n...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>{'help': 0.0, 'violence': 0.0, 'sleep': 0.0, '...</td>\n",
       "      <td>[(told, nsubj, m20), (said, nsubj, think), (kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>help opinions advice</td>\n",
       "      <td>okay open things past proud person anymore sto...</td>\n",
       "      <td>{'SYMPTOMS': ['anxiety']}</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>{'help': 0.02, 'violence': 0.02, 'sleep': 0.0,...</td>\n",
       "      <td>[(help, dobj, opinions), (help, dobj, advice),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help</td>\n",
       "      <td>removed</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>{'help': 0.5, 'violence': 0.0, 'sleep': 0.0, '...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ex got diagnosed bpd</td>\n",
       "      <td>going detail diagnosis explains sudden break u...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>{'help': 0.03, 'violence': 0.03, 'sleep': 0.0,...</td>\n",
       "      <td>[(going, dobj, diagnosis), (explains, dobj, up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>misdiagnosis bpd common asking diagnosed years...</td>\n",
       "      <td>reposting larger sub recommendation people sma...</td>\n",
       "      <td>{'NEURO-DEVELOPMENTAL DISORDERS': ['autism']}</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>{'help': 0.0, 'violence': 0.01, 'sleep': 0.0, ...</td>\n",
       "      <td>[(think, nsubj, bpd), (asking, dobj, years), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trouble identifying sexual orientation bpd lik...</td>\n",
       "      <td>grew dating men realized teenager like women k...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.9349</td>\n",
       "      <td>{'help': 0.0, 'violence': 0.03, 'sleep': 0.0, ...</td>\n",
       "      <td>[(likes, nsubj, trouble), (identifying, dobj, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>needing advice</td>\n",
       "      <td>posted sub earlier today having trouble believ...</td>\n",
       "      <td>{'SYMPTOMS': ['anxiety']}</td>\n",
       "      <td>-0.7003</td>\n",
       "      <td>{'help': 0.0, 'violence': 0.02, 'sleep': 0.0, ...</td>\n",
       "      <td>[(needing, dobj, advice), (posted, dobj, sub),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bpd</td>\n",
       "      <td>removed</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>{'help': 0.0, 'violence': 0.0, 'sleep': 0.0, '...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deal partner lacks empathy</td>\n",
       "      <td>tell overdramatic react feel straw decided tal...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>{'help': 0.02, 'violence': 0.02, 'sleep': 0.0,...</td>\n",
       "      <td>[(lacks, nsubj, partner), (lacks, dobj, empath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>husband allow pills bpd manage feelings medicine</td>\n",
       "      <td>dark moment life right husband controlling pos...</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>-0.8481</td>\n",
       "      <td>{'help': 0.02, 'violence': 0.05, 'sleep': 0.0,...</td>\n",
       "      <td>[(allow, nsubj, husband), (feelings, nsubj, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sure appointment working making dbt flash cards</td>\n",
       "      <td>appointment therapist week ended getting cance...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>{'help': 0.0, 'violence': 0.0, 'sleep': 0.02, ...</td>\n",
       "      <td>[(making, dobj, cards), (ended, nsubj, week), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>hi guys overwhelmed find having think episode ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.9769</td>\n",
       "      <td>{'help': 0.02, 'violence': 0.13, 'sleep': 0.0,...</td>\n",
       "      <td>[(find, nsubj, guys), (screaming, nsubj, end),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>murderous rage kind sorta</td>\n",
       "      <td>actually feeling positive time lately thought ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>-0.9795</td>\n",
       "      <td>{'help': 0.0, 'violence': 0.06, 'sleep': 0.0, ...</td>\n",
       "      <td>[(kind, nsubj, rage), (called, nsubj, brother)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                      life pointless   \n",
       "1                                           cold rage   \n",
       "2                                                know   \n",
       "3                                help opinions advice   \n",
       "4                                                help   \n",
       "5                                ex got diagnosed bpd   \n",
       "6   misdiagnosis bpd common asking diagnosed years...   \n",
       "7   trouble identifying sexual orientation bpd lik...   \n",
       "8                                      needing advice   \n",
       "9                                                 bpd   \n",
       "10                         deal partner lacks empathy   \n",
       "11   husband allow pills bpd manage feelings medicine   \n",
       "12    sure appointment working making dbt flash cards   \n",
       "13                                                      \n",
       "14                          murderous rage kind sorta   \n",
       "\n",
       "                                             selftext  \\\n",
       "0   think important life relationship like absolut...   \n",
       "1   hello fellow friends bpd spectrum discouraged ...   \n",
       "2   f20 bf m20 told today said wish better likes n...   \n",
       "3   okay open things past proud person anymore sto...   \n",
       "4                                             removed   \n",
       "5   going detail diagnosis explains sudden break u...   \n",
       "6   reposting larger sub recommendation people sma...   \n",
       "7   grew dating men realized teenager like women k...   \n",
       "8   posted sub earlier today having trouble believ...   \n",
       "9                                             removed   \n",
       "10  tell overdramatic react feel straw decided tal...   \n",
       "11  dark moment life right husband controlling pos...   \n",
       "12  appointment therapist week ended getting cance...   \n",
       "13  hi guys overwhelmed find having think episode ...   \n",
       "14  actually feeling positive time lately thought ...   \n",
       "\n",
       "                                       psy_labels  sentiment  \\\n",
       "0                                              {}     0.9501   \n",
       "1                         {'SYMPTOMS': ['anger']}    -0.9840   \n",
       "2                                              {}     0.8126   \n",
       "3                       {'SYMPTOMS': ['anxiety']}     0.9919   \n",
       "4                                              {}     0.4019   \n",
       "5                                              {}     0.9611   \n",
       "6   {'NEURO-DEVELOPMENTAL DISORDERS': ['autism']}     0.9231   \n",
       "7                                              {}     0.9349   \n",
       "8                       {'SYMPTOMS': ['anxiety']}    -0.7003   \n",
       "9                                              {}     0.0000   \n",
       "10                                             {}     0.6908   \n",
       "11                        {'SYMPTOMS': ['anger']}    -0.8481   \n",
       "12                                             {}     0.2500   \n",
       "13                                             {}    -0.9769   \n",
       "14                                             {}    -0.9795   \n",
       "\n",
       "                                 emotional_categories  \\\n",
       "0   {'help': 0.0, 'violence': 0.0, 'sleep': 0.0, '...   \n",
       "1   {'help': 0.01, 'violence': 0.01, 'sleep': 0.01...   \n",
       "2   {'help': 0.0, 'violence': 0.0, 'sleep': 0.0, '...   \n",
       "3   {'help': 0.02, 'violence': 0.02, 'sleep': 0.0,...   \n",
       "4   {'help': 0.5, 'violence': 0.0, 'sleep': 0.0, '...   \n",
       "5   {'help': 0.03, 'violence': 0.03, 'sleep': 0.0,...   \n",
       "6   {'help': 0.0, 'violence': 0.01, 'sleep': 0.0, ...   \n",
       "7   {'help': 0.0, 'violence': 0.03, 'sleep': 0.0, ...   \n",
       "8   {'help': 0.0, 'violence': 0.02, 'sleep': 0.0, ...   \n",
       "9   {'help': 0.0, 'violence': 0.0, 'sleep': 0.0, '...   \n",
       "10  {'help': 0.02, 'violence': 0.02, 'sleep': 0.0,...   \n",
       "11  {'help': 0.02, 'violence': 0.05, 'sleep': 0.0,...   \n",
       "12  {'help': 0.0, 'violence': 0.0, 'sleep': 0.02, ...   \n",
       "13  {'help': 0.02, 'violence': 0.13, 'sleep': 0.0,...   \n",
       "14  {'help': 0.0, 'violence': 0.06, 'sleep': 0.0, ...   \n",
       "\n",
       "                               semantic_relationships  \n",
       "0    [(ask, nsubj, relationship), (ask, dobj, goals)]  \n",
       "1   [(discouraged, nsubj, spectrum), (discouraged,...  \n",
       "2   [(told, nsubj, m20), (said, nsubj, think), (kn...  \n",
       "3   [(help, dobj, opinions), (help, dobj, advice),...  \n",
       "4                                                  []  \n",
       "5   [(going, dobj, diagnosis), (explains, dobj, up...  \n",
       "6   [(think, nsubj, bpd), (asking, dobj, years), (...  \n",
       "7   [(likes, nsubj, trouble), (identifying, dobj, ...  \n",
       "8   [(needing, dobj, advice), (posted, dobj, sub),...  \n",
       "9                                                  []  \n",
       "10  [(lacks, nsubj, partner), (lacks, dobj, empath...  \n",
       "11  [(allow, nsubj, husband), (feelings, nsubj, ma...  \n",
       "12  [(making, dobj, cards), (ended, nsubj, week), ...  \n",
       "13  [(find, nsubj, guys), (screaming, nsubj, end),...  \n",
       "14  [(kind, nsubj, rage), (called, nsubj, brother)...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.feature_engineering import create_rel_feature,create_psylabel_feature,create_sentiment_feature,create_emotional_categories_scores_feature\n",
    "tqdm.pandas()\n",
    "\n",
    "df_subset[\"psy_labels\"]=df_subset.progress_apply(create_psylabel_feature, axis=1)\n",
    "df_subset[\"sentiment\"]=df_subset.progress_apply(create_sentiment_feature, axis=1)\n",
    "df_subset[\"emotional_categories\"]=df_subset.progress_apply(create_emotional_categories_scores_feature, axis=1)\n",
    "df_subset[\"semantic_relationships\"]=df_subset.progress_apply(create_rel_feature, axis=1)\n",
    "\n",
    "# Cache it for further processing down the line.\n",
    "df_subset.to_csv(\"./data/SemanticsRel.csv\", index=False)\n",
    "df_subset[\n",
    "    [\n",
    "        \"title\",\n",
    "        \"selftext\",\n",
    "        \"psy_labels\",\n",
    "        \"sentiment\",\n",
    "        \"emotional_categories\",\n",
    "        \"semantic_relationships\",\n",
    "    ]\n",
    "].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Nodes\n",
    "\n",
    "Nodes have edges, attributes for MH disorders, wieghts and sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "738it [00:00, 4953.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Word1</th>\n",
       "      <th>Dependency</th>\n",
       "      <th>Word2</th>\n",
       "      <th>MHlabels</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPD</td>\n",
       "      <td>ask</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>relationship</td>\n",
       "      <td>{}</td>\n",
       "      <td>life pointless</td>\n",
       "      <td>think important life relationship like absolut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPD</td>\n",
       "      <td>ask</td>\n",
       "      <td>dobj</td>\n",
       "      <td>goals</td>\n",
       "      <td>{}</td>\n",
       "      <td>life pointless</td>\n",
       "      <td>think important life relationship like absolut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPD</td>\n",
       "      <td>discouraged</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>spectrum</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPD</td>\n",
       "      <td>discouraged</td>\n",
       "      <td>dobj</td>\n",
       "      <td>characteristics</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPD</td>\n",
       "      <td>wondering</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>levels</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BPD</td>\n",
       "      <td>experiencing</td>\n",
       "      <td>dobj</td>\n",
       "      <td>anger</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BPD</td>\n",
       "      <td>found</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>way</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BPD</td>\n",
       "      <td>found</td>\n",
       "      <td>dobj</td>\n",
       "      <td>blame</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BPD</td>\n",
       "      <td>find</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>understanding</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BPD</td>\n",
       "      <td>tend</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>ones</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BPD</td>\n",
       "      <td>tend</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>love</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BPD</td>\n",
       "      <td>extend</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>demonize</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BPD</td>\n",
       "      <td>lead</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>cases</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BPD</td>\n",
       "      <td>know</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>anger</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BPD</td>\n",
       "      <td>experience</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>guys</td>\n",
       "      <td>{'SYMPTOMS': ['anger']}</td>\n",
       "      <td>cold rage</td>\n",
       "      <td>hello fellow friends bpd spectrum discouraged ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subreddit         Word1 Dependency            Word2  \\\n",
       "0        BPD           ask      nsubj     relationship   \n",
       "1        BPD           ask       dobj            goals   \n",
       "2        BPD   discouraged      nsubj         spectrum   \n",
       "3        BPD   discouraged       dobj  characteristics   \n",
       "4        BPD     wondering      nsubj           levels   \n",
       "5        BPD  experiencing       dobj            anger   \n",
       "6        BPD         found      nsubj              way   \n",
       "7        BPD         found       dobj            blame   \n",
       "8        BPD          find      nsubj    understanding   \n",
       "9        BPD          tend      nsubj             ones   \n",
       "10       BPD          tend      nsubj             love   \n",
       "11       BPD        extend      nsubj         demonize   \n",
       "12       BPD          lead      nsubj            cases   \n",
       "13       BPD          know      nsubj            anger   \n",
       "14       BPD    experience      nsubj             guys   \n",
       "\n",
       "                   MHlabels           title  \\\n",
       "0                        {}  life pointless   \n",
       "1                        {}  life pointless   \n",
       "2   {'SYMPTOMS': ['anger']}       cold rage   \n",
       "3   {'SYMPTOMS': ['anger']}       cold rage   \n",
       "4   {'SYMPTOMS': ['anger']}       cold rage   \n",
       "5   {'SYMPTOMS': ['anger']}       cold rage   \n",
       "6   {'SYMPTOMS': ['anger']}       cold rage   \n",
       "7   {'SYMPTOMS': ['anger']}       cold rage   \n",
       "8   {'SYMPTOMS': ['anger']}       cold rage   \n",
       "9   {'SYMPTOMS': ['anger']}       cold rage   \n",
       "10  {'SYMPTOMS': ['anger']}       cold rage   \n",
       "11  {'SYMPTOMS': ['anger']}       cold rage   \n",
       "12  {'SYMPTOMS': ['anger']}       cold rage   \n",
       "13  {'SYMPTOMS': ['anger']}       cold rage   \n",
       "14  {'SYMPTOMS': ['anger']}       cold rage   \n",
       "\n",
       "                                             selftext  \n",
       "0   think important life relationship like absolut...  \n",
       "1   think important life relationship like absolut...  \n",
       "2   hello fellow friends bpd spectrum discouraged ...  \n",
       "3   hello fellow friends bpd spectrum discouraged ...  \n",
       "4   hello fellow friends bpd spectrum discouraged ...  \n",
       "5   hello fellow friends bpd spectrum discouraged ...  \n",
       "6   hello fellow friends bpd spectrum discouraged ...  \n",
       "7   hello fellow friends bpd spectrum discouraged ...  \n",
       "8   hello fellow friends bpd spectrum discouraged ...  \n",
       "9   hello fellow friends bpd spectrum discouraged ...  \n",
       "10  hello fellow friends bpd spectrum discouraged ...  \n",
       "11  hello fellow friends bpd spectrum discouraged ...  \n",
       "12  hello fellow friends bpd spectrum discouraged ...  \n",
       "13  hello fellow friends bpd spectrum discouraged ...  \n",
       "14  hello fellow friends bpd spectrum discouraged ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = []\n",
    "\n",
    "for idx, row in tqdm(df_subset.iterrows()):\n",
    "    subreddit = row[\"subreddit\"]\n",
    "    labels = row[\"psy_labels\"]\n",
    "    relationships = row[\"semantic_relationships\"]\n",
    "    title = row[\"title\"]\n",
    "    selftext = row[\"selftext\"]\n",
    "    for rel in relationships:\n",
    "        if len(rel) == 3:  # Ensure the tuple has three elements\n",
    "            word1, dep, word2 = rel\n",
    "            clean_data.append(\n",
    "                {\n",
    "                    \"Subreddit\": subreddit,\n",
    "                    \"Word1\": word1,\n",
    "                    \"Dependency\": dep,\n",
    "                    \"Word2\": word2,\n",
    "                    \"MHlabels\": labels,\n",
    "                    \"title\": title,\n",
    "                    \"selftext\": selftext,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Issue with relationship: {rel}\")\n",
    "\n",
    "clean_df = pd.DataFrame(clean_data)\n",
    "clean_df.to_csv(\"./data/GraphData.csv\", index=False)\n",
    "clean_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subreddit_x        Word1 Dependency         Word2  Occurrence  Subreddit_y\n",
      "0          BPD    diagnosed       dobj           bpd           9            1\n",
      "1          BPD         feel       dobj          love           4            1\n",
      "2          BPD         feel      nsubj           bpd           4            1\n",
      "3          BPD         feel      nsubj          help           4            1\n",
      "4          BPD         feel      nsubj        issues           5            1\n",
      "5          BPD         feel      nsubj          know           4            1\n",
      "6          BPD         feel      nsubj          life           4            1\n",
      "7          BPD         feel      nsubj          love           4            1\n",
      "8          BPD         feel      nsubj        people           8            1\n",
      "9          BPD         feel      nsubj  relationship           4            1\n",
      "10         BPD         feel      nsubj          talk           4            1\n",
      "11         BPD         feel      nsubj        things           4            1\n",
      "12         BPD         find      nsubj          time           4            1\n",
      "13         BPD        going       dobj       therapy           7            1\n",
      "14         BPD        going      nsubj            he           4            1\n",
      "15         BPD          got      nsubj        person           4            1\n",
      "16         BPD       having       dobj          time           5            1\n",
      "17         BPD  identifying       dobj        issues           4            1\n",
      "18         BPD         know      nsubj       friends           4            1\n",
      "19         BPD         know      nsubj          life           6            1\n",
      "20         BPD         know      nsubj          love           4            1\n",
      "21         BPD         know      nsubj        people          11            1\n",
      "22         BPD         know      nsubj        things           4            1\n",
      "23         BPD         know      nsubj          want           4            1\n",
      "24         BPD         live      nsubj        people           4            1\n",
      "25         BPD         love      nsubj        people           4            1\n",
      "26         BPD        makes       dobj         sense           4            1\n",
      "27         BPD         need       dobj        advice           4            1\n",
      "28         BPD         need       dobj          help           4            1\n",
      "29         BPD         need       dobj         space           4            1\n",
      "30         BPD            s      nsubj            he           8            1\n",
      "31         BPD         said      nsubj     therapist           5            1\n",
      "32         BPD         talk      nsubj       friends           4            1\n",
      "33         BPD        think      nsubj        people           8            1\n",
      "34         BPD         told      nsubj       friends           4            1\n",
      "35         BPD         told      nsubj        people           4            1\n",
      "36         BPD         want      nsubj          life           6            1\n",
      "37         BPD         want      nsubj          love           4            1\n",
      "38         BPD         want      nsubj        people           5            1\n"
     ]
    }
   ],
   "source": [
    "# Grouping the DataFrame by 'Subreddit', 'Word1', 'Dependency', and 'Word2' and counting occurrences\n",
    "grouped = (\n",
    "    clean_df.groupby([\"Subreddit\", \"Word1\", \"Dependency\", \"Word2\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"Occurrence\")\n",
    ")\n",
    "\n",
    "# Filter out entries where Word1 and Word2 are not in the English dictionary\n",
    "# filtered_relationships = multiple_subreddit_relationships[\n",
    "#     (multiple_subreddit_relationships['Word1'].isin(english_words)) &\n",
    "#     (multiple_subreddit_relationships['Word2'].isin(english_words))\n",
    "# ]\n",
    "\n",
    "# Define a regular expression pattern to match only alphanumeric words\n",
    "pattern = re.compile(r\"^[a-zA-Z]+$\")\n",
    "\n",
    "# Filter out entries where Word1 and Word2 contain only alphanumeric characters\n",
    "filtered_relationships = grouped[\n",
    "    (grouped[\"Word1\"].str.match(pattern)) & (grouped[\"Word2\"].str.match(pattern))\n",
    "]\n",
    "\n",
    "# Filtering relationships occurring more than three times within each subreddit\n",
    "common_relationships = filtered_relationships[filtered_relationships[\"Occurrence\"] > 3]\n",
    "\n",
    "\n",
    "# Grouping the DataFrame by 'Word1', 'Dependency', and 'Word2' to count unique occurrences across subreddits\n",
    "relationship_counts = (\n",
    "    common_relationships.groupby([\"Word1\", \"Dependency\", \"Word2\"])\n",
    "    .agg({\"Subreddit\": \"nunique\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Filter relationships occurring in only one subreddit\n",
    "single_subreddit_relationships = relationship_counts[\n",
    "    relationship_counts[\"Subreddit\"] == 1\n",
    "]\n",
    "\n",
    "# Merge to keep only the relationships occurring in one subreddit from common_relationships\n",
    "filtered_common_relationships = pd.merge(\n",
    "    common_relationships,\n",
    "    single_subreddit_relationships,\n",
    "    on=[\"Word1\", \"Dependency\", \"Word2\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "print(filtered_common_relationships)\n",
    "filtered_common_relationships.to_csv(\"SemanticsRelFiltered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some entries have word1 and word2 which are not actual words but numbers or mispelled words. Even though there was a chance that these were to be filtered due to occurrence should be more than 3, some weren't. At this point i was going to use the NLTK library to check for english words, but upon implementing, some important words like 'zyprexa' was eliminated since it's not included in the corpus. However this is an important entry and therefore should remain. a more crude filter, removing numbers only entries was implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "\"zyprexa\" in english_vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
