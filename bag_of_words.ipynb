{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "Created by Owen Fava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "nltk.download (\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mental_disorders(dataset_path: str, column: str):\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "    mental_disorders = dataset[column].unique()\n",
    "    lower_cased_mental_disorders = [x.lower() for x in mental_disorders]\n",
    "    \n",
    "    return dataset, lower_cased_mental_disorders\n",
    "\n",
    "dataset, mental_disorders = get_mental_disorders(\"data/mental_disorders_reddit.csv\", \"subreddit\")\n",
    "print(\"Records retrieved: \", len(dataset))\n",
    "print(mental_disorders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mental_disorder_data(mental_disorder: str, dataset: pd.DataFrame):\n",
    "    data = dataset.loc[dataset[\"subreddit\"].str.lower() == mental_disorder]\n",
    "    \n",
    "    return data\n",
    "\n",
    "anxiety_data = get_mental_disorder_data(\"anxiety\", dataset)\n",
    "print(\"Anxiety data retrieved: \", len(anxiety_data))\n",
    "\n",
    "bpd_data = get_mental_disorder_data(\"bpd\", dataset)\n",
    "print(\"BPD data retrieved: \", len(bpd_data))\n",
    "\n",
    "depression_data = get_mental_disorder_data(\"depression\", dataset)\n",
    "print(\"Depression data retrieved: \", len(depression_data))\n",
    "\n",
    "mental_illness_data = get_mental_disorder_data(\"mentalillness\", dataset)\n",
    "print(\"Mental illness data retrieved: \", len(mental_illness_data))\n",
    "\n",
    "schizophrenia_data = get_mental_disorder_data(\"schizophrenia\", dataset)\n",
    "print(\"Schizophrenia data retrieved: \", len(schizophrenia_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data_columns_and_clean(data: str, columns: list[str], new_column_name: str):\n",
    "    # Read value at specific index\n",
    "    # print(combined_data.iloc[0][new_column_name])\n",
    "    combined_data = pd.concat([data[column] for column in columns], ignore_index=True)\n",
    "    combined_cleaned_data = pd.DataFrame({new_column_name: combined_data}).dropna()\n",
    "\n",
    "    return combined_cleaned_data\n",
    "\n",
    "anxiety_data = combine_data_columns_and_clean(anxiety_data, [\"title\", \"selftext\"], \"anxiety_combined_title_selftext\")\n",
    "print(\"Anxiety data retrieved: \", len(anxiety_data))\n",
    "\n",
    "bpd_data = combine_data_columns_and_clean(bpd_data, [\"title\", \"selftext\"], \"bpd_combined_title_selftext\")\n",
    "print(\"BPD data retrieved: \", len(bpd_data))\n",
    "\n",
    "depression_data = combine_data_columns_and_clean(depression_data, [\"title\", \"selftext\"], \"depression_combined_title_selftext\")\n",
    "print(\"Depression data retrieved: \", len(depression_data))\n",
    "\n",
    "mental_illness_data = combine_data_columns_and_clean(mental_illness_data, [\"title\", \"selftext\"], \"mental_illness_combined_title_selftext\")\n",
    "print(\"Mental illness data retrieved: \", len(mental_illness_data))\n",
    "\n",
    "schizophrenia_data = combine_data_columns_and_clean(schizophrenia_data, [\"title\", \"selftext\"], \"schizophrenia_combined_title_selftext\")\n",
    "print(\"Schizophrenia data retrieved: \", len(schizophrenia_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(data):\n",
    "    tokenisation = [word for sentence in data for word in word_tokenize(sentence)]\n",
    "    \n",
    "    return tokenisation\n",
    "\n",
    "anxiety_data = tokenize_text(anxiety_data[\"anxiety_combined_title_selftext\"])\n",
    "bpd_data = tokenize_text(bpd_data[\"bpd_combined_title_selftext\"])\n",
    "depression_data = tokenize_text(depression_data[\"depression_combined_title_selftext\"])\n",
    "mental_illness_data = tokenize_text(mental_illness_data[\"mental_illness_combined_title_selftext\"])\n",
    "schizophrenia_data = tokenize_text(schizophrenia_data[\"schizophrenia_combined_title_selftext\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(data, toLower: bool):\n",
    "    result = []\n",
    "\n",
    "    if toLower:\n",
    "        result = [text.lower() for text in data]\n",
    "    else:\n",
    "        result = [text.upper() for text in data]\n",
    "\n",
    "    return result\n",
    "\n",
    "anxiety_data = case_folding(anxiety_data, True)\n",
    "bpd_data = case_folding(bpd_data, True)\n",
    "depression_data = case_folding(depression_data, True)\n",
    "mental_illness_data = case_folding(mental_illness_data, True)\n",
    "schizophrenia_data = case_folding(schizophrenia_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discard_non_alphabetical_words(data):\n",
    "    result = [text for text in data if text.isalpha()]\n",
    "    \n",
    "    return result\n",
    "\n",
    "anxiety_data = discard_non_alphabetical_words(anxiety_data)\n",
    "bpd_data = discard_non_alphabetical_words(bpd_data)\n",
    "depression_data = discard_non_alphabetical_words(depression_data)\n",
    "mental_illness_data = discard_non_alphabetical_words(mental_illness_data)\n",
    "schizophrenia_data = discard_non_alphabetical_words(schizophrenia_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total count of rows:\n",
    "total_count_of_rows = len(anxiety_data) + len(bpd_data) + len(depression_data) + len(mental_illness_data)+ len(schizophrenia_data)\n",
    "print(\"Total rows: \", total_count_of_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    result = [text for text in data if (not text in stopwords.words(\"english\"))]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# def lemmatize_text(data):\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     lemmas = [lemmatizer.lemmatize(text) for text in data]\n",
    "\n",
    "#     return lemmas\n",
    "\n",
    "def clean_data_and_export_to_csv(data, csv_file_name: str, column_name: str):\n",
    "    removed_stop_words_data = remove_stop_words(data)\n",
    "    # lemmatized_data = lemmatize_text(removed_stop_words_data)\n",
    "\n",
    "    if not os.path.splitext(csv_file_name)[1]:\n",
    "        csv_file_name = csv_file_name + \".csv\"\n",
    "    \n",
    "    with open(csv_file_name, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([column_name])\n",
    "        for item in removed_stop_words_data:\n",
    "            writer.writerow([item])\n",
    "    \n",
    "clean_data_and_export_to_csv(anxiety_data, \"cleaned_anxiety_data\", \"anxiety-data\")\n",
    "print(\"Anxiety data done\")\n",
    "\n",
    "clean_data_and_export_to_csv(bpd_data, \"cleaned_bpd_data\", \"bpd-data\")\n",
    "print(\"BPD data done\")\n",
    "\n",
    "clean_data_and_export_to_csv(depression_data, \"cleaned_depression_data\", \"depression-data\")\n",
    "print(\"Depression data done\")\n",
    "\n",
    "clean_data_and_export_to_csv(mental_illness_data, \"cleaned_mental_illness_data\", \"mental-illness-data\")\n",
    "print(\"Mental Illness data done\")\n",
    "\n",
    "clean_data_and_export_to_csv(schizophrenia_data, \"cleaned_schizophrenia_data\", \"schizophrenia-data\")\n",
    "print(\"Schizophrenia data done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DATA FROM CLEANED CSVS\n",
    "# Read data from CSV file\n",
    "def read_from_csv_to_list(csv_file_name: str, column_name: str):\n",
    "    if not os.path.splitext(csv_file_name)[1]:\n",
    "        csv_file_name = csv_file_name + \".csv\"\n",
    "\n",
    "    data = pd.read_csv(csv_file_name)\n",
    "    data = data[column_name].tolist()\n",
    "\n",
    "    return data\n",
    "\n",
    "anxiety_cleaned_data = read_from_csv_to_list(\"cleaned_anxiety_data\", \"anxiety-data\")\n",
    "print(f\"Retrived {len(anxiety_cleaned_data)} rows of data for anxiety\")\n",
    "\n",
    "bpd_cleaned_data = read_from_csv_to_list(\"cleaned_bpd_data\", \"bpd-data\")\n",
    "print(f\"Retrived {len(bpd_cleaned_data)} rows of data for BPD\")\n",
    "\n",
    "depression_cleaned_data = read_from_csv_to_list(\"cleaned_depression_data\", \"depression-data\")\n",
    "print(f\"Retrived {len(depression_cleaned_data)} rows of data for depression\")\n",
    "\n",
    "mental_illness_cleaned_data = read_from_csv_to_list(\"cleaned_mental_illness_data\", \"mental-illness-data\")\n",
    "print(f\"Retrived {len(mental_illness_cleaned_data)} rows of data for mental illness\")\n",
    "\n",
    "schizophrenia_cleaned_data = read_from_csv_to_list(\"cleaned_schizophrenia_data\", \"schizophrenia-data\")\n",
    "print(f\"Retrived {len(schizophrenia_cleaned_data)} rows of data for schizophrenia\")\n",
    "\n",
    "def lemmatize_text_and_write_frequency_to_csv(data, csv_file_name: str):\n",
    "    if not os.path.splitext(csv_file_name)[1]:\n",
    "        csv_file_name = csv_file_name + \".csv\"\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(str(word)) for word in data]\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(lemmatized_text)\n",
    "\n",
    "    # Sort the words by frequency in descending order\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Write the results to a CSV file\n",
    "    with open(csv_file_name, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Word\", \"Frequency\"])\n",
    "        for word, count in sorted_words:\n",
    "            writer.writerow([word, count])\n",
    "\n",
    "    return lemmatized_text\n",
    "\n",
    "anxiety_lemmatized_data = lemmatize_text_and_write_frequency_to_csv(anxiety_cleaned_data, \"anxiety_bag_of_words\")\n",
    "print(\"Anxiety data lemmitization done\")\n",
    "print(f\"Anxiety lemmmas: {len(anxiety_lemmatized_data)}\")\n",
    "\n",
    "bpd_lemmatized_data = lemmatize_text_and_write_frequency_to_csv(bpd_cleaned_data, \"bpd_bag_of_words\")\n",
    "print(\"BPD data lemmitization done\")\n",
    "print(f\"BPD lemmmas: {len(bpd_lemmatized_data)}\")\n",
    "\n",
    "depression_lemmatized_data = lemmatize_text_and_write_frequency_to_csv(depression_cleaned_data, \"depression_bag_of_words\")\n",
    "print(\"Depression data lemmitization done\")\n",
    "print(f\"Depressionn lemmmas: {len(depression_lemmatized_data)}\")\n",
    "\n",
    "mental_illness_lemmatized_data = lemmatize_text_and_write_frequency_to_csv(mental_illness_cleaned_data, \"mental_illness_bag_of_words\")\n",
    "print(\"Mental Illness data lemmitization one\")\n",
    "print(f\"Mental illness lemmmas: {len(mental_illness_lemmatized_data)}\")\n",
    "\n",
    "schizophrenia_lemmatized_data = lemmatize_text_and_write_frequency_to_csv(schizophrenia_cleaned_data, \"schizophrenia_bag_of_words\")\n",
    "print(\"Schizophrenia data lemmitization done\")\n",
    "print(f\"Schizophrenia lemmmas: {len(schizophrenia_lemmatized_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bag_of_words_visual(csv_file_name: str):\n",
    "    if not os.path.splitext(csv_file_name)[1]:\n",
    "        csv_file_name = csv_file_name + \".csv\"\n",
    "    \n",
    "    data = pd.read_csv(csv_file_name)\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    word_counts = dict(zip(data[\"Word\"], data[\"Frequency\"]))\n",
    "\n",
    "    # Generate WordCloud\n",
    "    wordcloud = WordCloud(width=800, height=800, background_color='white').generate_from_frequencies(word_counts)\n",
    "\n",
    "    plt.figure(figsize=(8, 8), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "generate_bag_of_words_visual(\"anxiety_bag_of_words\")\n",
    "generate_bag_of_words_visual(\"bpd_bag_of_words\")\n",
    "generate_bag_of_words_visual(\"depression_bag_of_words\")\n",
    "generate_bag_of_words_visual(\"mental_illness_bag_of_words\")\n",
    "generate_bag_of_words_visual(\"schizophrenia_bag_of_words\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
