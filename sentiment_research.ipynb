{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Research\n",
    "\n",
    "By Adam Darmanin\n",
    "\n",
    "## Literature and References\n",
    "\n",
    "- [Empath: Understanding Topic Signals in Large-Scale Text](https://www.researchgate.net/publication/301872654_Empath_Understanding_Topic_Signals_in_Large-Scale_Text)\n",
    "- [Turbo-charge your spaCy NLP pipeline](https://towardsdatascience.com/turbo-charge-your-spacy-nlp-pipeline-551435b664ad)\n",
    "- [VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text](https://www.researchgate.net/publication/275828927_VADER_A_Parsimonious_Rule-based_Model_for_Sentiment_Analysis_of_Social_Media_Text)\n",
    "- [VADER Github](https://github.com/cjhutto/vaderSentiment)\n",
    "- [5 Lesser-Known Python Libraries for Your Next NLP Project](https://towardsdatascience.com/5-lesser-known-python-libraries-for-your-next-nlp-project-ff13fc652553)\n",
    "- [The Development and Psychometric Properties of LIWC-22](https://www.liwc.app/static/documents/LIWC-22%20Manual%20-%20Development%20and%20Psychometrics.pdf)\n",
    "- [AFINN Github](https://github.com/fnielsen/afinn)\n",
    "- [Harvard IV-4 General Inquirer Dictionaries](https://inquirer.sites.fas.harvard.edu/homecat.htm)\n",
    "- [TextBlob: Simplified Text Processing](https://textblob.readthedocs.io/en/dev/)\n",
    "- [Empathy-Mental-Health](https://github.com/behavioral-data/Empathy-Mental-Health)\n",
    "- [A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support](https://arxiv.org/pdf/2009.08441.pdf)\n",
    "- [Psychological Education Health Assessment Problems Based on Improved Constructive Neural Network](https://www.frontiersin.org/articles/10.3389/fpsyg.2022.943146/full)\n",
    "- [Collection of Mental Health and AI Papers](https://github.com/Sahandfer/EMPaper)\n",
    "\n",
    "\n",
    "## Method\n",
    "\n",
    "Each framework will be tested against these 2 requirements:\n",
    "1. **Sentiment Analysis** and its various nuances, with specific focus on mental health.\n",
    "2. **Severity of Mental Health** if it's dictionaries, lexicons, or general architecture can operate on this domain.\n",
    "\n",
    "### VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "\n",
    "Lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\n",
    "It can be used to analyze the sentiment of Reddit posts (OPs) to infer mental health indicators, although with some limitations.\n",
    "\n",
    "1. VADER provides a compound score that combines the positive, negative, and neutral scores of a text.\n",
    "2. It might identify negative sentiments, which could be indicative of poor mental health - but it's not a Mental Health tool and won't capture complexity or expressions.\n",
    "\n",
    "VADER has a compound score as unidimensional measure of sentiment for the post's text:\n",
    "- positive sentiment: compound score >= 0.05\n",
    "- neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "- negative sentiment: compound score <= -0.05\n",
    "\n",
    "###  LIWC-22\n",
    "\n",
    "Linguistic Inquiry and Word Count (LIWC) is the gold standard in software for analyzing word use. Sadly it through paid licenses only.\n",
    "\n",
    "AFINN is a sentiment analysis tool specifically designed for analyzing the sentiment of texts, particularly those found on social media platforms. Here's an overview of AFINN, its scoring mechanism, and its application in the context of social media and mental health analysis:\n",
    "\n",
    "### AFINN\n",
    "\n",
    "lexicon with each word assigned a sentiment score. Scoring is context-agnostic and not nuanced. Good for online slang, not for mental health domain.\n",
    "\n",
    "1. Word and text aggragate scoring.\n",
    "2. Scoring is context-agnostic and not nuanced.\n",
    "\n",
    "AFINN has a simple scoring:\n",
    "- positive sentiment: compound score >= 3\n",
    "- negative sentiment: compound score <= -3\n",
    "\n",
    "### Text Blob\n",
    "\n",
    "Pre-trained model on large datasets for sentiment, its a black box.\n",
    "\n",
    "1. TextBlob's sentiment analysis provides two scores: `polarity` and `subjectivity`.\n",
    "2. The model is not related to mental health nor social media.\n",
    "\n",
    "- **Polarity**: It ranges from -1 to 1, where -1 indicates a negative sentiment, 1 indicates a positive sentiment, and 0 indicates neutrality. Polarity is calculated based on the presence and combination of positive and negative words in the text.\n",
    "- **Subjectivity**: This score ranges from 0 to 1. A score closer to 0 is more objective, and a score closer to 1 is more subjective. Subjectivity here refers to the expression of personal opinions, emotions, or judgments in the text, as opposed to factual information.\n",
    "\n",
    "### Empath\n",
    "\n",
    "Empath is a text analysis tool that works by identifying and categorizing words and phrases in a given text into different human-understandable themes or categories.\n",
    "If is **different** from others, because it covers a broader range of over 200 categories such as sadness, anger, family, violence, medical_emergency, etc.\n",
    "\n",
    "1. Scores by Category. When you pass text to Empath, it analyzes the text and maps the words and phrases to its predefined categories. Each category contains a set of related words and phrases. For example, the \"anger\" category might include words like \"angry\", \"fury\", \"rage\", etc.\n",
    "2. Very flexible, can be applied for mental health and reddit.\n",
    "\n",
    "Scoring:\n",
    "- Empath counts the occurrences of words and phrases in the text that fall into each category. The score for a category is the count of these occurrences. If a piece of text does not contain any words related to a certain category, the score for that category will be zero. This count is normalized accroding to document lenght.\n",
    "- Scores have to be interpreted or copmared to a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib.sanitze_util import clean_text_batch\n",
    "\n",
    "tqdm.pandas()\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "df = pd.read_csv(\"./data/depression-sample.csv\")\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "df = df.dropna(subset=[\"body\"])\n",
    "df[\"body\"] = df[\"body\"].astype(str)\n",
    "df = df[\n",
    "    (df[\"body\"].str.len() > 2) & (\n",
    "        ~df[\"body\"].str.contains(\"\\[deleted\\]\", na=False))\n",
    "]\n",
    "\n",
    "cleaned_texts = clean_text_batch(df[\"body\"], multi_proc=True)\n",
    "\n",
    "df[\"cleaned_body\"] = cleaned_texts\n",
    "df[[\"body\", \"cleaned_body\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vader_sentiment(text):\n",
    "    score = sia.polarity_scores(text)\n",
    "    return score[\"compound\"] if score is not None else np.NaN\n",
    "\n",
    "\n",
    "sentiments = [\n",
    "    get_vader_sentiment(text)\n",
    "    for text in tqdm(cleaned_texts, desc=\"Analysing Sentiment (VADER)\")\n",
    "]\n",
    "\n",
    "df[\"VADER\"] = sentiments\n",
    "df[[\"body\", \"cleaned_body\", \"VADER\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_df = df[[\"body\", \"VADER\"]]\n",
    "vader_df = vader_df.sort_values(by=\"VADER\", ascending=False)\n",
    "\n",
    "\n",
    "top_vader_df = vader_df.head(5)\n",
    "bottom_vader_df = vader_df.tail(5)\n",
    "top_vader_df[\"body\"].values, bottom_vader_df[\"body\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afinn = Afinn()\n",
    "\n",
    "\n",
    "def get_afinn_sentiment(text):\n",
    "    return afinn.score(text)\n",
    "\n",
    "\n",
    "sentiments = [\n",
    "    get_afinn_sentiment(text)\n",
    "    for text in tqdm(cleaned_texts, desc=\"Analysing Sentiment (Afinn)\")\n",
    "]\n",
    "\n",
    "df[\"Afinn\"] = sentiments\n",
    "df[[\"body\", \"cleaned_body\", \"Afinn\", \"VADER\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def get_blob_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment\n",
    "\n",
    "\n",
    "sentiments = [\n",
    "    get_blob_sentiment(text)\n",
    "    for text in tqdm(cleaned_texts, desc=\"Analysing Sentiment (Blob)\")\n",
    "]\n",
    "\n",
    "\n",
    "df[\"Blob\"] = sentiments\n",
    "df[[\"body\", \"cleaned_body\", \"Blob\", \"Afinn\", \"VADER\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empath import Empath\n",
    "\n",
    "lexicon = Empath()\n",
    "\n",
    "def get_empath_sentiment(text):\n",
    "    return lexicon.analyze(\n",
    "        text, categories=[\"positive_emotion\", \"negative_emotion\"], normalize=True\n",
    "    )\n",
    "sentiments = [\n",
    "    get_empath_sentiment(text)\n",
    "    for text in tqdm(cleaned_texts, desc=\"Analysing Sentiment (Empath)\")\n",
    "]\n",
    "df[\"Empath\"] = sentiments\n",
    "df[[\"body\", \"cleaned_body\", \"Empath\", \"Blob\", \"Afinn\", \"VADER\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empath import Empath\n",
    "\n",
    "lexicon = Empath()\n",
    "\n",
    "\n",
    "def get_empath_categories(text):\n",
    "    return lexicon.analyze(text, normalize=True)\n",
    "\n",
    "\n",
    "cats = [\n",
    "    get_empath_categories(text)\n",
    "    for text in tqdm(cleaned_texts, desc=\"Analysing Sentiment (Empath)\")\n",
    "]\n",
    "\n",
    "\n",
    "df[\"cats\"] = cats\n",
    "empath_df = df[[\"body\", \"cats\"]]\n",
    "empath_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empath is of interest, it is able to create a matrix of categories the text can go to, additionally we can create our own categories which it will train agains a reddit model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "agg_cats = empath_df[\"cats\"].progress_apply(pd.Series).sum()\n",
    "agg_cats = agg_cats[agg_cats > 20]\n",
    "agg_cats = agg_cats.sort_values(ascending=False)\n",
    "\n",
    "top_20_cats = agg_cats.head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 16))\n",
    "top_20_cats.plot(kind=\"barh\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Empath Category Scores\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empath_scores = empath_df[\"cats\"].progress_apply(pd.Series)\n",
    "max_score_texts = {}\n",
    "for category in top_20_cats.index:\n",
    "    max_idx = df_empath_scores[category].idxmax()\n",
    "    max_score_texts[category] = df.loc[max_idx, \"body\"]\n",
    "\n",
    "max_score_texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
